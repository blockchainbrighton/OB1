<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>OB1 #1 - Audional Art</title><style>body{background-color:#000000;display:flex;justify-content:center;align-items:center;height:100vh;margin:0}img {width: auto;height: auto;max-width: 60%;max-height: 80vh;object-fit: contain;aspect-ratio: 1 / 1;}
</style></head><body>
<img id="OB1_Image" src="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQ...
<audio id="audionalData" loop data-audionalSampleName="808 Kick Drum">
<source src="data:audio/wav;base64,UklGRk6GAQBXQVZFS...
Your browser does not support the audio element.
</audio>
<script>
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();

    const bpm = 78;
    const beatDurationSeconds = 60 / bpm;

    let isLooping = false;
    let audioBuffer = null;
    let nextNoteTime = audioContext.currentTime;
    let attackFadeDuration = 0.01; // Initial attack fade duration in seconds, adjustable
    let tailFadeDuration = 0.001; // Initial tail fade duration in seconds, adjustable

    const gainNode = audioContext.createGain();
    gainNode.connect(audioContext.destination);

    async function fetchAndDecodeAudio(elementId) {
        const audioElement = document.getElementById(elementId);
        const sourceElement = audioElement.querySelector('source');
        const audioSrc = sourceElement ? sourceElement.src : audioElement.src;

        try {
            const response = await fetch(audioSrc);
            const arrayBuffer = await response.arrayBuffer();
            audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        } catch (error) {
            console.error("Error fetching or decoding audio data:", error);
        }
    }

    function scheduleNextNote() {
        if (!isLooping || !audioBuffer) return;

        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(gainNode);

        gainNode.gain.cancelScheduledValues(nextNoteTime);
        // Apply attack fade
        gainNode.gain.setValueAtTime(0.001, nextNoteTime);
        gainNode.gain.linearRampToValueAtTime(1, nextNoteTime + attackFadeDuration);

        // Schedule the note to start at nextNoteTime
        source.start(nextNoteTime);

        // Apply tail fade if the sample is longer than the beat duration
        if (audioBuffer.duration > beatDurationSeconds) {
            const crossFadeStartTime = nextNoteTime + beatDurationSeconds - tailFadeDuration;
            gainNode.gain.linearRampToValueAtTime(0.001, crossFadeStartTime);
        }

        nextNoteTime += beatDurationSeconds; // Schedule the next note

        const delayUntilNextNote = Math.max(nextNoteTime - audioContext.currentTime, 0) * 1000;
        setTimeout(scheduleNextNote, delayUntilNextNote);
    }

    function playAudioBuffer() {
        if (!isLooping) {
            isLooping = true;
            nextNoteTime = audioContext.currentTime; // Reset nextNoteTime to current time
            scheduleNextNote(); // Start scheduling notes
        }
    }

    function stopAudioPlayback() {
        isLooping = false;
    }

    document.getElementById("OB1_Image").addEventListener("click", async () => {
        console.log("Click detected...");
        if (!audioBuffer) {
            await fetchAndDecodeAudio("audionalData");
        }
        if (isLooping) {
            stopAudioPlayback();
        } else {
            playAudioBuffer();
        }
    });
</script>
<script src="OB1_CommsAndHotkeys.js"></script>
</body>
</html>
